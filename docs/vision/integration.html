<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Vision: Integration Map</title>
    <link rel="stylesheet" href="../site.css" />
    <script src="../site-nav.js" defer></script>
  </head>
  <body>
    <header>
      <h1>Integration Map</h1>
      <p>How all vision domains connect and what remains to be built.</p>
    </header>
    <main>
      <div class="card">
        <div class="nav">
          <a href="index.html">Vision Home</a>
          <a href="regulated.html">Regulated Industry</a>
          <a href="literature.html">Literary Analysis</a>
          <a href="system2.html">System 2 + LLM</a>
          <a href="rag-thinking-db.html">RAG + Thinking DB</a>
          <a href="science.html">Scientific Review</a>
          <a href="synthetic-data.html">Synthetic Data</a>
          <a href="agents.html">Agents + Tools</a>
          <a href="trustworthy-ai.html">Trustworthy AI</a>
          <a href="integration.html">Integration Map</a>
        </div>

        <h2>Shared backbone</h2>
        <ul>
          <li><strong>Common meaning layer</strong>: CNL/DSL as the single, deterministic representation.</li>
          <li><strong>Strict vocabulary</strong>: every domain adds a schema, not ad-hoc text.</li>
          <li><strong>Checkable results</strong>: certificates/witnesses for trust and audit.</li>
        </ul>

        <h2>Cross-domain links</h2>
        <ul>
          <li>Regulated compliance and trustworthy AI share policy libraries and audit output.</li>
          <li>Scientific review and synthetic data share probabilistic engines and schema modeling.</li>
          <li>Agent planning and System 2 LLM workflows share action schemas and verification loops.</li>
          <li>Literary analysis uses the same contradiction engine as compliance, just with a different vocabulary.</li>
          <li>RAG and thinking databases connect all domains through a shared reasoning layer and provenance.</li>
        </ul>

        <h2>What still needs to be built</h2>
        <ul>
          <li><strong>CNL authoring tools</strong>: validators, editors, and feedback loops.</li>
          <li><strong>Extraction pipelines</strong>: safely map text into CNL without losing semantics.</li>
          <li><strong>Domain libraries</strong>: shared vocabularies and rule templates per industry.</li>
          <li><strong>Certificate checkers</strong>: more trusted checkers for numeric and domain-specific backends.</li>
          <li><strong>Evaluation harnesses</strong>: test suites for contradiction detection and coverage.</li>
        </ul>

        <h2>Why this matters</h2>
        <p>
          UBHNL is not just a solver. It is a structured System 2 layer that keeps AI outputs grounded in
          explicit meaning, with traceable and checkable results. That makes it suitable for high-risk domains
          where auditability is mandatory.
        </p>
      </div>
    </main>
  </body>
</html>
