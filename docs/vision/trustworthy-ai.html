<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Vision: Trustworthy AI</title>
    <link rel="stylesheet" href="../site.css" />
    <script src="../site-nav.js" defer></script>
  </head>
  <body>
    <header>
      <h1>Trustworthy AI, Bias, and Governance</h1>
      <p>Make policies explicit and auditable, and detect rule-level bias or conflicts.</p>
    </header>
    <main>
      <div class="card">
        <div class="nav">
          <a href="index.html">Vision Home</a>
          <a href="regulated.html">Regulated Industry</a>
          <a href="literature.html">Literary Analysis</a>
          <a href="system2.html">System 2 + LLM</a>
          <a href="rag-thinking-db.html">RAG + Thinking DB</a>
          <a href="science.html">Scientific Review</a>
          <a href="synthetic-data.html">Synthetic Data</a>
          <a href="agents.html">Agents + Tools</a>
          <a href="trustworthy-ai.html">Trustworthy AI</a>
          <a href="integration.html">Integration Map</a>
        </div>

        <h2>What this enables</h2>
        <ul>
          <li><strong>Policy checks</strong>: encode fairness and compliance constraints as rules.</li>
          <li><strong>Conflict detection</strong>: identify incompatible policies and hidden assumptions.</li>
          <li><strong>Audit trails</strong>: every decision references its formal origin.</li>
        </ul>

        <h2>Workflow (practical)</h2>
        <ol>
          <li>Define governance vocabulary (protected attributes, decision outcomes).</li>
          <li>Encode policies in CNL/DSL with explicit constraints.</li>
          <li>Evaluate model outputs against policies and detect violations.</li>
          <li>Report conflicts with origins and certificates.</li>
        </ol>

        <h2>Outputs you can expect</h2>
        <ul>
          <li>Policy compliance reports with traceability.</li>
          <li>Formal explanations for violations or exclusions.</li>
          <li>Counterexamples that reveal bias or inconsistent rules.</li>
        </ul>

        <h2>Limits and constraints</h2>
        <ul>
          <li>Fairness notions must be modeled explicitly; no implicit definitions.</li>
          <li>Quantitative fairness metrics require dedicated fragments or numeric encodings.</li>
        </ul>

        <h2>What we still need</h2>
        <ul>
          <li>Reusable governance libraries for common standards.</li>
          <li>Integration with model evaluation pipelines and datasets.</li>
          <li>Benchmark suites for policy consistency and bias detection.</li>
        </ul>
      </div>
    </main>
  </body>
</html>
