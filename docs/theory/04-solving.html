<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Theory 04: The Solving Strategy</title>
    <link rel="stylesheet" href="../site.css" />
    <script src="../site-nav.js" defer></script>
  </head>
  <body class="with-diagram">
    <header>
      <h1>Theory 04 â€” Solving Strategy: Verification and Evidence</h1>
      <p>Establishing truth through checkable witnesses and certificates.</p>
    </header>
    <main>
      <div class="card">
        <div class="draft">DRAFT: academic tutorial on solving and certificates.</div>

        <div class="nav">
          <a href="03-ubh-ir.html">Prev: UBH Kernel</a>
          <a href="index.html">Theory Index</a>
          <a href="05-languages.html">Next: Languages</a>
        </div>

        <section>
          <h2>The Epistemology of Proof</h2>
          <p>
            In a rigorous reasoning system, an unsupported claim is equivalent to an unknown value. UBHNL adheres to the principle of <strong>Result Verification</strong>: no claim of truth (SAT) or impossibility (UNSAT) is accepted unless it is accompanied by checkable evidence. This requirement shifts the burden of trust from the complexity of the solver's internal algorithms to the simplicity of the kernel's verification logic.
          </p>
        </section>

        <section>
          <h2>The Tri-State Result Model</h2>
          <p>
            Unlike binary systems that return only "True" or "False," UBHNL utilizes a tri-state status model to accurately reflect the certainty of the reasoning process.
          </p>
          <p>
            The <strong>SAT (Satisfiable)</strong> status indicates that a consistent assignment has been found. This result is only accepted if it includes a <strong>Witness</strong> (a model) that the kernel can deterministically evaluate. Conversely, the <strong>UNSAT (Unsatisfiable)</strong> status indicates that no consistent assignment exists. This claim must be supported by a <strong>Certificate</strong> (such as a DRAT or LRAT proof trace) that demonstrates the inevitable contradiction. If a result cannot be reached within the allocated resource budget or if a checkable proof cannot be generated, the system returns <strong>UNKNOWN</strong>, ensuring that unverifiable claims never pollute the knowledge base.
          </p>
        </section>

        <section>
          <h2>The Hybrid SAT + Native XOR Engine</h2>
          <p>
            To achieve high efficiency across diverse logical fragments, UBHNL employs a <strong>Hybrid Solver Architecture</strong>. This system orchestrates two distinct reasoning strategies:
          </p>
          <ul>
            <li><strong>CDCL SAT Solving:</strong> Optimized for the non-linear constraints typically found in "If-Then" rules and boolean dependencies.</li>
            <li><strong>XOR-Linear Reasoning:</strong> Utilizes algebraic methods (such as Gaussian Elimination) to solve linear equations over GF(2) directly, avoiding the exponential expansion that occurs when XOR constraints are bit-blasted into pure CNF.</li>
          </ul>
          <p>
            The communication between these strategies allows the solver to prune the search space much more effectively than either method could achieve in isolation.
          </p>
        </section>

        <section>
          <h2>Explainability and Origin Tracking</h2>
          <p>
            When a contradiction is detected, the system provides an <strong>Unsat Core</strong>. This core is a minimal set of constraints that are mutually exclusive. By leveraging the system's internal <strong>Origin Tracking</strong>, UBHNL can map these low-level Boolean contradictions back to the original lines of CNL text authored by the user. This provides a clear, auditable trail that explains <em>why</em> a theory is inconsistent, grounded in the user's own vocabulary.
          </p>
        </section>

        <section>
          <h2>Research Horizons: Human-Readable Proofs</h2>
          <p>
            While the current system produces robust machine-verifiable certificates, work is ongoing to implement <strong>Proof Translation</strong>. This involves converting raw mathematical traces into high-level, human-readable narratives. The goal is to allow a domain expert to review a formal proof of unsatisfiability using the same natural language patterns they used to author the rules.
          </p>
        </section>

        <div class="footer-links">
          <p>Read about certificates: <a href="../mdview.html?file=specs/DS/DS14-certificate-formats-verification.md">DS-014: Certificate Formats</a>.</p>
        </div>
      </div>
    </main>
  </body>
</html>
